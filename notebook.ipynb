{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "## Variables for configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_features = ['cp','restecg', 'slope','ca', 'restwm']\n",
    "# list the datasets that should be used in the current run\n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"long-beach-va\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "# set pandas to show all columns of the df when using the display function\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to read the dataset into a csv formatted string\n",
    "# the name is used as a delimiter here because it is the last feature and common among all entrys \n",
    "def read_raw_data(file_path:str):\n",
    "    with open(file_path) as file:\n",
    "        file_string = file.read()\n",
    "        # remove unnecessary linebreaks\n",
    "        file_string = file_string.replace(\"\\n\",\" \")\n",
    "        # break lines after name to separate measurements by line (name is a constant and the last attribute)\n",
    "        file_string = file_string.replace(\"name \",\"name\\n\")\n",
    "        # separate columns by \",\" instead of \" \".\n",
    "        file_string = file_string.replace(\" \",\",\")\n",
    "        return file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the specified datasets into the df \n",
    "from io import StringIO\n",
    "df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(StringIO(read_raw_data(\"./Data/\"+ dataset +\".data\")), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    df = pd.concat([df,dataset_df ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"id\", \"ccf\", \"age\", \"sex\", \"painloc\", \"painexer\" , \"relrest\" , \"pncaden\" , \"cp\", \"trestbps\", \"htn\", \"chol\", \"smoke\", \"cigs\", \"years\", \"fbs\", \"dm\", \"famhist\", \"restecg\", \"ekgmo\", \"ekgday\", \"ekgyr\", \"dig\", \"prop\", \"nitr\", \"pro\", \"diuretic\", \"proto\", \"thaldur\", \"thaltime\", \"met\", \"thalach\", \"thalrest\", \"tpeakbps\", \"tpeakbpd\", \"dummy\", \"trestbpd\", \"exang\", \"xhypo\", \"oldpeak\", \"slope\", \"rldv5\", \"rldv5e\", \"ca\", \"restckm\", \"exerckm\", \"restef\", \"restwm\", \"exeref\", \"exerwm\", \"thal\", \"thalsev\", \"thalpul\", \"earlobe\", \"cmo\", \"cday\", \"cyr\", \"num\", \"lmt\", \"ladprox\", \"laddist\", \"diag\", \"cxmain\", \"ramus\", \"om1\", \"om2\", \"rcaprox\", \"rcadist\", \"lvx1\", \"lvx2\", \"lvx3\", \"lvx4\", \"lvf\", \"cathef\", \"junk\", \"name\", \"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "       id  ccf  age  sex  painloc  painexer  relrest  pncaden  cp  trestbps  \\\n0    1254    0   40    1      1.0       0.0      0.0      NaN   2     140.0   \n1    1255    0   49    0      1.0       0.0      0.0      NaN   3     160.0   \n2    1256    0   37    1      1.0       0.0      0.0      NaN   2     130.0   \n3    1257    0   48    0      1.0       1.0      1.0      NaN   4     138.0   \n4    1258    0   54    1      1.0       0.0      1.0      NaN   3     150.0   \n..    ...  ...  ...  ...      ...       ...      ...      ...  ..       ...   \n894   200    0   54    0      1.0       1.0      1.0      NaN   4     127.0   \n895   201    0   62    1      0.0       0.0      0.0      NaN   1       NaN   \n896   202    0   55    1      1.0       1.0      1.0      NaN   4     122.0   \n897   116    0   58    1      1.0       1.0      1.0      NaN   4       NaN   \n898   160    0   62    1      1.0       0.0      0.0      NaN   2     120.0   \n\n     htn   chol  smoke  cigs  years  fbs   dm  famhist  restecg  ekgmo  \\\n0    0.0  289.0    NaN   NaN    NaN  0.0  NaN      NaN      0.0   12.0   \n1    1.0  180.0    NaN   NaN    NaN  0.0  NaN      NaN      0.0   11.0   \n2    0.0  283.0    NaN   NaN    NaN  0.0  NaN      NaN      1.0   11.0   \n3    0.0  214.0    NaN   NaN    NaN  0.0  NaN      NaN      0.0    9.0   \n4    0.0    NaN    NaN   NaN    NaN  0.0  NaN      NaN      0.0    7.0   \n..   ...    ...    ...   ...    ...  ...  ...      ...      ...    ...   \n894  0.0  333.0    0.0   0.0    0.0  1.0  NaN      1.0      1.0    6.0   \n895  0.0  139.0    1.0  15.0   30.0  0.0  NaN      0.0      1.0    NaN   \n896  1.0  223.0    1.0  20.0   40.0  1.0  NaN      0.0      1.0    5.0   \n897  0.0  385.0    0.0  10.0   20.0  1.0  1.0      1.0      2.0    NaN   \n898  1.0  254.0    0.0   0.0    0.0  0.0  NaN      0.0      2.0    1.0   \n\n     ekgday  ekgyr  dig  prop  nitr  pro  diuretic  proto  thaldur  thaltime  \\\n0      16.0   84.0  0.0   0.0   0.0  0.0       0.0  150.0     18.0       NaN   \n1      16.0   84.0  0.0   0.0   0.0  0.0       0.0    NaN     10.0       9.0   \n2      21.0   84.0  0.0   0.0   0.0  0.0       0.0  100.0     10.0       NaN   \n3      21.0   84.0  0.0   0.0   0.0  0.0       0.0   50.0      5.0       4.0   \n4      25.0   84.0  0.0   0.0   1.0  1.0       0.0   25.0      2.0       NaN   \n..      ...    ...  ...   ...   ...  ...       ...    ...      ...       ...   \n894     6.0   83.0  0.0   1.0   1.0  0.0       0.0    1.0      7.5       NaN   \n895     NaN    NaN  NaN   NaN   NaN  NaN       NaN    NaN      NaN       NaN   \n896     2.0   86.0  0.0   1.0   1.0  0.0       1.0    5.0      5.3       NaN   \n897     NaN    NaN  NaN   NaN   NaN  NaN       NaN    NaN      NaN       NaN   \n898    24.0   83.0  0.0   1.0   0.0  0.0       0.0    1.0      6.7       NaN   \n\n     met  thalach  thalrest  tpeakbps  tpeakbpd  dummy  trestbpd  exang  \\\n0    7.0    172.0      86.0     200.0     110.0  140.0      86.0    0.0   \n1    7.0    156.0     100.0     220.0     106.0  160.0      90.0    0.0   \n2    5.0     98.0      58.0     180.0     100.0  130.0      80.0    0.0   \n3    4.0    108.0      54.0     210.0     106.0  138.0      86.0    1.0   \n4    3.0    122.0      74.0     130.0     100.0  150.0      90.0    0.0   \n..   ...      ...       ...       ...       ...    ...       ...    ...   \n894  8.0    154.0      83.0     158.0      84.0  127.0      78.0    0.0   \n895  NaN      NaN       NaN       NaN       NaN    NaN       NaN    NaN   \n896  5.0    100.0      74.0     210.0     100.0  122.0      70.0    0.0   \n897  NaN      NaN       NaN       NaN       NaN    NaN       NaN    NaN   \n898  7.0     93.0      67.0     164.0     110.0  120.0      80.0    1.0   \n\n     xhypo  oldpeak  slope  rldv5  rldv5e  ca  restckm  exerckm  restef  \\\n0      0.0      0.0    NaN   26.0    20.0 NaN      NaN      NaN     NaN   \n1      0.0      1.0    2.0   14.0    13.0 NaN      NaN      NaN     NaN   \n2      0.0      0.0    NaN   17.0    14.0 NaN      NaN      NaN     NaN   \n3      0.0      1.5    2.0   19.0    22.0 NaN      NaN      NaN     NaN   \n4      1.0      0.0    NaN   13.0     9.0 NaN      NaN      NaN     NaN   \n..     ...      ...    ...    ...     ...  ..      ...      ...     ...   \n894    0.0      0.0    NaN   20.0    20.0 NaN      NaN      NaN     NaN   \n895    NaN      NaN    NaN    NaN     NaN NaN      NaN      NaN    0.41   \n896    0.0      0.0    NaN    6.0     4.0 NaN      NaN      NaN    0.39   \n897    NaN      NaN    NaN    NaN     NaN NaN      NaN      NaN     NaN   \n898    0.0      0.0    NaN   21.0    17.0 NaN      NaN      NaN     NaN   \n\n     restwm  exeref  exerwm  thal  thalsev  thalpul  earlobe   cmo  cday  \\\n0       NaN     NaN     NaN   NaN      NaN      NaN      NaN  12.0  20.0   \n1       NaN     NaN     NaN   NaN      NaN      NaN      NaN  11.0  20.0   \n2       NaN     NaN     NaN   NaN      NaN      NaN      NaN  11.0  26.0   \n3       NaN     NaN     NaN   NaN      NaN      NaN      NaN   9.0  30.0   \n4       NaN     NaN     NaN   NaN      NaN      NaN      NaN   7.0  30.0   \n..      ...     ...     ...   ...      ...      ...      ...   ...   ...   \n894     NaN     NaN     NaN   NaN      NaN      NaN      NaN   6.0  29.0   \n895     1.0     NaN     NaN   NaN      NaN      NaN      NaN   5.0  26.0   \n896     3.0     NaN     NaN   6.0      2.0      NaN      NaN   4.0  17.0   \n897     NaN     NaN     NaN   NaN      NaN      NaN      NaN   2.0  16.0   \n898     NaN     NaN     NaN   NaN      NaN      NaN      NaN   6.0  20.0   \n\n      cyr  num  lmt  ladprox  laddist  diag  cxmain  ramus  om1  om2  rcaprox  \\\n0    84.0    0  NaN      NaN      NaN   NaN     NaN    NaN  NaN  NaN      NaN   \n1    84.0    1  NaN      NaN      2.0   NaN     NaN    NaN  NaN  NaN      NaN   \n2    84.0    0  NaN      NaN      NaN   NaN     NaN    NaN  NaN  NaN      NaN   \n3    84.0    3  NaN      2.0      NaN   NaN     2.0    NaN  NaN  NaN      2.0   \n4    84.0    0  NaN      NaN      NaN   NaN     1.0    NaN  NaN  NaN      1.0   \n..    ...  ...  ...      ...      ...   ...     ...    ...  ...  ...      ...   \n894  83.0    1  1.0      1.0      1.0   1.0     2.0    1.0  1.0  1.0      1.0   \n895  86.0    0  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0   \n896  86.0    2  1.0      2.0      1.0   1.0     1.0    1.0  1.0  1.0      2.0   \n897  83.0    0  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0   \n898  83.0    1  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      2.0   \n\n     rcadist  lvx1  lvx2  lvx3  lvx4  lvf  cathef  junk  name        dataset  \n0        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n1        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n2        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n3        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n4        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n..       ...   ...   ...   ...   ...  ...     ...   ...   ...            ...  \n894      1.0   1.0   1.0   1.0   1.0  1.0    0.76   5.6  name  long-beach-va  \n895      1.0   1.0   1.0   1.0   1.0  2.0    0.62   3.5  name  long-beach-va  \n896      1.0   1.0   1.0   1.0   1.0  1.0    0.69   5.6  name  long-beach-va  \n897      1.0   1.0   1.0   1.0   1.0  1.0    0.81   6.0  name  long-beach-va  \n898      1.0   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name  long-beach-va  \n\n[899 rows x 77 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ccf</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>painloc</th>\n      <th>painexer</th>\n      <th>relrest</th>\n      <th>pncaden</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>htn</th>\n      <th>chol</th>\n      <th>smoke</th>\n      <th>cigs</th>\n      <th>years</th>\n      <th>fbs</th>\n      <th>dm</th>\n      <th>famhist</th>\n      <th>restecg</th>\n      <th>ekgmo</th>\n      <th>ekgday</th>\n      <th>ekgyr</th>\n      <th>dig</th>\n      <th>prop</th>\n      <th>nitr</th>\n      <th>pro</th>\n      <th>diuretic</th>\n      <th>proto</th>\n      <th>thaldur</th>\n      <th>thaltime</th>\n      <th>met</th>\n      <th>thalach</th>\n      <th>thalrest</th>\n      <th>tpeakbps</th>\n      <th>tpeakbpd</th>\n      <th>dummy</th>\n      <th>trestbpd</th>\n      <th>exang</th>\n      <th>xhypo</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>rldv5</th>\n      <th>rldv5e</th>\n      <th>ca</th>\n      <th>restckm</th>\n      <th>exerckm</th>\n      <th>restef</th>\n      <th>restwm</th>\n      <th>exeref</th>\n      <th>exerwm</th>\n      <th>thal</th>\n      <th>thalsev</th>\n      <th>thalpul</th>\n      <th>earlobe</th>\n      <th>cmo</th>\n      <th>cday</th>\n      <th>cyr</th>\n      <th>num</th>\n      <th>lmt</th>\n      <th>ladprox</th>\n      <th>laddist</th>\n      <th>diag</th>\n      <th>cxmain</th>\n      <th>ramus</th>\n      <th>om1</th>\n      <th>om2</th>\n      <th>rcaprox</th>\n      <th>rcadist</th>\n      <th>lvx1</th>\n      <th>lvx2</th>\n      <th>lvx3</th>\n      <th>lvx4</th>\n      <th>lvf</th>\n      <th>cathef</th>\n      <th>junk</th>\n      <th>name</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1254</td>\n      <td>0</td>\n      <td>40</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>140.0</td>\n      <td>0.0</td>\n      <td>289.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>16.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>150.0</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>172.0</td>\n      <td>86.0</td>\n      <td>200.0</td>\n      <td>110.0</td>\n      <td>140.0</td>\n      <td>86.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>26.0</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>20.0</td>\n      <td>84.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1255</td>\n      <td>0</td>\n      <td>49</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>160.0</td>\n      <td>1.0</td>\n      <td>180.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>16.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>156.0</td>\n      <td>100.0</td>\n      <td>220.0</td>\n      <td>106.0</td>\n      <td>160.0</td>\n      <td>90.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>14.0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>20.0</td>\n      <td>84.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1256</td>\n      <td>0</td>\n      <td>37</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>130.0</td>\n      <td>0.0</td>\n      <td>283.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>11.0</td>\n      <td>21.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>98.0</td>\n      <td>58.0</td>\n      <td>180.0</td>\n      <td>100.0</td>\n      <td>130.0</td>\n      <td>80.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>26.0</td>\n      <td>84.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1257</td>\n      <td>0</td>\n      <td>48</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>138.0</td>\n      <td>0.0</td>\n      <td>214.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>21.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>108.0</td>\n      <td>54.0</td>\n      <td>210.0</td>\n      <td>106.0</td>\n      <td>138.0</td>\n      <td>86.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>19.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>30.0</td>\n      <td>84.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1258</td>\n      <td>0</td>\n      <td>54</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>25.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>122.0</td>\n      <td>74.0</td>\n      <td>130.0</td>\n      <td>100.0</td>\n      <td>150.0</td>\n      <td>90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>30.0</td>\n      <td>84.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>200</td>\n      <td>0</td>\n      <td>54</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>127.0</td>\n      <td>0.0</td>\n      <td>333.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>83.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>7.5</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>154.0</td>\n      <td>83.0</td>\n      <td>158.0</td>\n      <td>84.0</td>\n      <td>127.0</td>\n      <td>78.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>29.0</td>\n      <td>83.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.76</td>\n      <td>5.6</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>201</td>\n      <td>0</td>\n      <td>62</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>139.0</td>\n      <td>1.0</td>\n      <td>15.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.41</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>26.0</td>\n      <td>86.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.62</td>\n      <td>3.5</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>202</td>\n      <td>0</td>\n      <td>55</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>122.0</td>\n      <td>1.0</td>\n      <td>223.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>40.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>86.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>5.3</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>100.0</td>\n      <td>74.0</td>\n      <td>210.0</td>\n      <td>100.0</td>\n      <td>122.0</td>\n      <td>70.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.39</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>17.0</td>\n      <td>86.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.69</td>\n      <td>5.6</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>116</td>\n      <td>0</td>\n      <td>58</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>385.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>20.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>16.0</td>\n      <td>83.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.81</td>\n      <td>6.0</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>160</td>\n      <td>0</td>\n      <td>62</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>120.0</td>\n      <td>1.0</td>\n      <td>254.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>24.0</td>\n      <td>83.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.7</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>93.0</td>\n      <td>67.0</td>\n      <td>164.0</td>\n      <td>110.0</td>\n      <td>120.0</td>\n      <td>80.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>21.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>20.0</td>\n      <td>83.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n  </tbody>\n</table>\n<p>899 rows Ã— 77 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace -9 by NaN (according to Data/heart-disease.names)\n",
    "df.replace(-9,np.float64(\"NaN\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# we want to predict whether a patient has any heart disease, not the type/degree of heart disease as recommended by the UCI https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "df[df[\"num\"]>1] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment of different scales in the datasets\n",
    "the reasons for this processing are laid out further in the analysis notebook\n",
    "## met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data:\n",
    "sns.boxplot(x=\"met\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# the measurements of switzerland do not seem valid -> replace with NaN\n",
    "df.loc[df[\"dataset\"] == \"switzerland\", \"met\"] = np.float64(\"NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rldv5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data: \n",
    "sns.boxplot(x=\"rldv5e\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# the measurements of cleveland do not seem valid -> replace with NaN\n",
    "df.loc[df[\"dataset\"] == \"cleveland\", \"rldv5e\"] = np.float64(\"NaN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "irrelevant_columns = [\n",
    "    \"id\", # A id is not relevant for a model\n",
    "    \"ccf\", # the social security number does not influence if you have a heart disease or not\n",
    "    \"pncaden\", # sum of painlox painexer relrest -> the features are already in the dataset -> drop because it is a duplicate\n",
    "    \"ekgmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"name\" # Constant\n",
    "]\n",
    "df.drop(irrelevant_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unexplained_columns = [\n",
    "    \"restckm\", # irrelevant according to the uci\n",
    "    \"exerckm\", # irrelevant according to the uci\n",
    "    \"thalsev\", # irrelevant according to the uci\n",
    "    \"thalpul\", # irrelevant according to the uci\n",
    "    \"earlobe\", # Constant\n",
    "    \"lvx1\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx2\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx3\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx4\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvf\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"dummy\", # no description available -> from the name does not seem relevant\n",
    "    'junk'\n",
    "]\n",
    "df.drop(unexplained_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hidden_identifier = [\n",
    "    'lmt',      # Left main truck\n",
    "    'ladprox',  # Proximal left anterior descending artery\n",
    "    'laddist',  # Distal left anterior descending artery\n",
    "    'diag',     # Diagonal branches\n",
    "    'cxmain',   # Circumflex\n",
    "    'ramus',    # Ramus intermedius\n",
    "    'om1',      # First obtuse marginal branch\n",
    "    'om2',      # Second obtuse marginal branch\n",
    "    'rcaprox',  # Proximal right coronary artery\n",
    "    'rcadist',  # Distal right coronary artery\n",
    "]\n",
    "df.drop(hidden_identifier, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from  sklearn.naive_bayes import *\n",
    "\n",
    "estimators=[\n",
    "    # {\"estimator\": CatBoostClassifier(random_state=42, thread_count=-1, silent= True), \"parameters\": {'estimator__depth':[None] + [*range(1,200)],\n",
    "    #                                                                                                  'estimator__n_estimators':range(10,1000, 100),\n",
    "    #                                                                                                  'estimator__learning_rate':[0.001,0.01,0.1,0.2,0.3],\n",
    "    #                                                                                                  'estimator__l2_leaf_reg':range(5,100, 5),\n",
    "    #                                                                                                  'estimator__border_count':range(5,200, 5),\n",
    "    #                                                                                                  'estimator__ctr_border_count':range(5,200, 5)\n",
    "    #                                                                                                  }},\n",
    "    # {\"estimator\": XGBClassifier(random_state=42, n_jobs=1), \"parameters\": {'estimator__max_depth': [None] + [*range(1,200)],\n",
    "    #                                                                        'estimator__n_estimators': range(10,1000, 100),\n",
    "    #                                                                         'estimator__learning_rate':[0.001,0.01,0.1,0.2,0.3]}},\n",
    "    # {\"estimator\": SVC(random_state=42, tol=0.01), \"parameters\": {'estimator__C': [110,120,130,140,150],\n",
    "    #                                                              'estimator__gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    #                                                              'estimator__degree': [3,4,5,6],\n",
    "    #                                                              'estimator__kernel':['linear', 'rbf', 'poly', 'sigmoid'] }}, # '\n",
    "    # {\"estimator\": BernoulliNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1)}},\n",
    "    # {\"estimator\": CategoricalNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1)}},\n",
    "    # {\"estimator\": ComplementNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1),\n",
    "    #                                              'estimator__norm':[True,False]}},\n",
    "    # {\"estimator\": GaussianNB(), \"parameters\": {}},\n",
    "    # {\"estimator\": MultinomialNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1)}},\n",
    "    # {\"estimator\": DecisionTreeClassifier(random_state=42), \"parameters\": {'estimator__criterion':['gini','entropy', 'log_loss'],\n",
    "    #                                                                       'estimator__max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150],\n",
    "    #                                                                       'estimator__min_samples_split': range(2,20),\n",
    "    #                                                                       'estimator__min_samples_leaf': range(2,20)}},\n",
    "    {\"estimator\": KNeighborsClassifier(), \"parameters\": {'estimator__n_neighbors': range(2, 100,5),\n",
    "                                                         'estimator__weights': ['uniform','distance'],\n",
    "                                                         'estimator__p': [1,2]}},\n",
    "    # {\"estimator\": RandomForestClassifier(random_state=42, n_jobs=1), \"parameters\": {'estimator__n_estimators':range(10,1000, 100)}},\n",
    "    # {\"estimator\": SGDClassifier(max_iter=1000000), \"parameters\": {'estimator__loss':['log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    #                                               'estimator__penalty':['l1','l2','elasticnet'],\n",
    "    #                                               'estimator__alpha' : np.arange(1,40,1)}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "scalers = [\n",
    "    {\"scaler\": MaxAbsScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": MinMaxScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": Normalizer(), \"parameters\": {'scaler__norm': ['l1', 'l2', 'max']}},\n",
    "    # box-cox is not used because the dataset contains negative values\n",
    "    {\"scaler\": PowerTransformer(), \"parameters\": {'scaler__standardize':[True,False]}},\n",
    "    # quantile-range is not used for selecting the model in order to reduce compute time\n",
    "    {\"scaler\": RobustScaler(), \"parameters\": {'scaler__with_centering': [ True, False],'scaler__with_scaling': [ True, False]}},\n",
    "    {\"scaler\": StandardScaler(), \"parameters\": {'scaler__with_mean': [ True, False],'scaler__with_std': [ True, False]}},\n",
    "    {\"scaler\": 'passthrough', \"parameters\": {}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "imputers = [\n",
    "    {\"imputer\": SimpleImputer(), \"parameters\": {'impute__strategy' : ['mean', 'median', 'most_frequent']}},\n",
    "    # KNN imputer is not used after inspection of the runtime with the KNN classifier (see KNN_classifier_with_KNN_and_simple_imputer.json)\n",
    "    # {\"imputer\": KNNImputer(), \"parameters\": {'impute__n_neighbors': range(2, 10,1)}},\n",
    "    # iterative imputer is not used because bugs were observed during the usage of this experimental feature\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "samplers = ['passthrough', RandomOverSampler(),RandomUnderSampler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "general_parameters = {\n",
    "    #values are selected based on analysis in Analyse.ipynb\n",
    "    'drop_columns__minimum_percentage_to_be_dropped': [0,4,8,20,35,60,75,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns smoke, cigs and years describe whether a respondent smokes or not. Smoke does this by being binary coded, while years describes the number of years a person has smoked. Cigs describes how many cigarettes the person smokes a day. Due to the high number of missing values in smoke, it is enriched with the years and cigs columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DataframeSmokeTransformer:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        # we do not enrich smoke if cigs and years are conflicting\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of years is 0 and smoke does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] == 0) & ~(input_df['cigs'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of years is larger than 0 and smoke does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] > 0) & (input_df['cigs'] != 0),'smoke'] = 1\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of smoke is 0 and years does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] == 0) & ~(input_df['years'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of cigs is larger than 0 and years does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] > 0) & (input_df['years'] != 0),'smoke'] = 1\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # there is nothing to be fitted here because this handling is not split specific\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "class DropColumnsBasedOnMinimumPercentageToBeDropped:\n",
    "    def __init__(self):\n",
    "        self.minimum_percentage_to_be_dropped = 100\n",
    "        self.fitted = False\n",
    "        self.valuesToKeep = []\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.minimum_percentage_to_be_dropped = params.get('minimum_percentage_to_be_dropped')\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        if self.fitted:\n",
    "            return input_df[input_df.columns.intersection(self.valuesToKeep)]\n",
    "        else:\n",
    "            raise NotFittedError()\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # calculate percentage of missing values for each column and store in a dictionary\n",
    "        percentage_missing = (X.isna().sum()/len(df)*100).to_dict()\n",
    "        # generate list of columns to keep\n",
    "        self.valuesToKeep = [key for key, val in percentage_missing.items() if val <= self.minimum_percentage_to_be_dropped]\n",
    "        self.fitted = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FixCommonEncodingErrors:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        input_df = input_df.copy(deep=True)\n",
    "        # if cholesterin is 0 it was not measured\n",
    "        input_df.loc[input_df['chol'] == 0,'chol'] =  np.float64(\"NaN\")\n",
    "        # leave the dead ones behind\n",
    "        # drop entries with a blood pressure of 0\n",
    "        input_df.loc[input_df['trestbps'] == 0,'trestbps'] =  np.float64(\"NaN\")\n",
    "        # is a binary variable (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[df['prop'].isin([0,1]) == False,'prop' ] = np.float64(\"NaN\")\n",
    "        # is a variable that has the values 0-3 by definition  (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[input_df['ca'] >3 ,'ca'] =  np.float64(\"NaN\")\n",
    "        # transform proto according to possible values from data/ask-detrano\n",
    "        input_df.loc[input_df['proto'] == 200,'proto'] =  9\n",
    "        input_df.loc[input_df['proto'] == 175,'proto'] =  8\n",
    "        input_df.loc[input_df['proto'] == 150,'proto'] =  7\n",
    "        input_df.loc[input_df['proto'] == 130,'proto'] =  6\n",
    "        input_df.loc[input_df['proto'] == 125,'proto'] =  5\n",
    "        input_df.loc[input_df['proto'] == 100,'proto'] = 4\n",
    "        input_df.loc[input_df['proto'] == 75,'proto'] = 3\n",
    "        input_df.loc[input_df['proto'] == 50,'proto'] = 2\n",
    "        input_df.loc[input_df['proto'] == 50,'proto'] = 1\n",
    "        #set all other values to NaN\n",
    "        input_df.loc[input_df['proto'].isin([*range(1,13)]) == False, 'proto'] = np.float64(\"NaN\")\n",
    "\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# assumption the dictionaries are of equal structure\n",
    "def merge_dict(dict1, dict2):\n",
    "    for key, val in dict1.items():\n",
    "        # merge nested dictionaries\n",
    "        if type(val) == dict:\n",
    "            dict1[key] = merge_dict(dict1[key], dict2[key])\n",
    "        # if value of dict1 is a list -> append values of dict2[key] to that list\n",
    "        elif type(val) == list:\n",
    "            if type(dict2[key]) == list:\n",
    "                dict1[key] = [ *dict1[key], *dict2[key]]\n",
    "            else:\n",
    "                dict1[key] = [*dict1[key], dict2[key]]\n",
    "        else:\n",
    "            # merge values into a new list\n",
    "            dict1[key] = [val, dict2[key]]\n",
    "\n",
    "    return dict1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# It is necessary to write a separate score function to obtain and save results from the respective cross validations later on (outer loop of nested cv).\n",
    "# This procedure requires working with pickle, as it is not possible to interact with data structures from the notebook (even if they are marked as global), as make_scorer later creates a deepCopy of this function and thus the data structures are also copied. The same applies to the parameters that could be passed to this function in the makeScorer function.\n",
    "def classification_report_with_auc_score(y_true, y_pred):\n",
    "    # calculate the score that will be returned to the cross validation to obtain the optimal hyperparameters\n",
    "    current_roc_auc_score = roc_auc_score(y_true, y_pred)\n",
    "    #transform confusion matrix to dictionary\n",
    "    confusion_matrix_dict = {}\n",
    "    for idxRow, row in np.ndenumerate(confusion_matrix(y_true, y_pred)):\n",
    "        confusion_matrix_dict[str(idxRow)] = row\n",
    "    # check if pickle was created by another cross validation loop\n",
    "    if os.path.exists('temp.pickle'):\n",
    "        with open(\"temp.pickle\", \"rb\") as temp_file:\n",
    "            # read pickled dictionary of previous cross validation loop\n",
    "            report = pickle.load(temp_file)\n",
    "            # append current score\n",
    "            report[\"auc\"].append(current_roc_auc_score)\n",
    "            # merge classification reports\n",
    "            report['classification_report'] = merge_dict(report['classification_report'], classification_report(y_true, y_pred, output_dict=True))\n",
    "            # merge confusion matrix dictionaries\n",
    "            report['confusion_matrix'] = merge_dict(report['confusion_matrix'], confusion_matrix_dict)\n",
    "    else:\n",
    "        #create dictionary for first pickle\n",
    "        report = {'classification_report': classification_report(y_true, y_pred, output_dict=True),\n",
    "                  \"auc\": [current_roc_auc_score],\n",
    "                  'confusion_matrix': confusion_matrix_dict\n",
    "                  }\n",
    "    # write report dictionary to pickle-file\n",
    "    with open('temp.pickle', 'wb') as temp_file:\n",
    "        pickle.dump(report, temp_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # return calculated roc_auc_score for evaluation in cross validation\n",
    "    return current_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from imblearn.base import BaseSampler\n",
    "import json\n",
    "\n",
    "#custom Encoder for serialization of output\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if type(obj) == range:\n",
    "            return [*obj]\n",
    "        if isinstance(obj, BaseSampler):\n",
    "            return obj.__class__.__name__\n",
    "        return super(CustomEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/memory.py\", line 32, in <module>\n",
      "    from ._store_backends import StoreBackendBase, FileSystemStoreBackend\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_store_backends.py\", line 15, in <module>\n",
      "    from .backports import concurrency_safe_rename\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/backports.py\", line 13, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "    import numpy as np\n",
      "  File \"<frozen importlib._bootstrap>\", line 1024, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 174, in __exit__\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "  File \"<frozen importlib._bootstrap>\", line 134, in release\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "KeyboardInterrupt\n",
      "    __import__(pkg_name)\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/__init__.py\", line 120, in <module>\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/__init__.py\", line 120, in <module>\n",
      "    from .parallel import Parallel\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py\", line 26, in <module>\n",
      "    from .parallel import Parallel\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py\", line 26, in <module>\n",
      "    from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 17, in <module>\n",
      "    from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 17, in <module>\n",
      "    from .pool import MemmappingPool\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/pool.py\", line 31, in <module>\n",
      "    from .pool import MemmappingPool\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/pool.py\", line 31, in <module>\n",
      "    from ._memmapping_reducer import get_memmapping_reducers\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_memmapping_reducer.py\", line 8, in <module>\n",
      "    from ._memmapping_reducer import get_memmapping_reducers\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_memmapping_reducer.py\", line 8, in <module>\n",
      "    from mmap import mmap\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "    from mmap import mmap\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "KeyboardInterrupt\n",
      "    __import__(pkg_name)\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/__init__.py\", line 120, in <module>\n",
      "    from .parallel import Parallel\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py\", line 26, in <module>\n",
      "    from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 17, in <module>\n",
      "    from .pool import MemmappingPool\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/pool.py\", line 31, in <module>\n",
      "    from ._memmapping_reducer import get_memmapping_reducers\n",
      "  File \"/Users/lasse/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_memmapping_reducer.py\", line 8, in <module>\n",
      "    from mmap import mmap\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [83], line 37\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 37\u001B[0m     auc_best \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrid_search_estimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_scorer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclassification_report_with_auc_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mraise\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m     grid_search_estimator\u001B[38;5;241m.\u001B[39mfit(X, y)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py:1048\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1048\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1049\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py:864\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    863\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 864\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    865\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py:782\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    781\u001B[0m job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 782\u001B[0m job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    783\u001B[0m \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    784\u001B[0m \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    785\u001B[0m \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callback:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py:263\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    264\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py:263\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    264\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    685\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 686\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1378\u001B[0m \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1379\u001B[0m \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    819\u001B[0m         )\n\u001B[1;32m    820\u001B[0m     )\n\u001B[0;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py:1061\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1061\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/parallel.py:938\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    937\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 938\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    939\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/concurrent/futures/_base.py:453\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/UniMannheim-DataMining/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m     \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m     gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [83], line 76\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     75\u001B[0m     measurements \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 76\u001B[0m measurements\u001B[38;5;241m.\u001B[39mappend(\u001B[43moutput_dict\u001B[49m)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m     78\u001B[0m     json\u001B[38;5;241m.\u001B[39mdump({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeasurements\u001B[39m\u001B[38;5;124m\"\u001B[39m: measurements}, file, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m CustomEncoder)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'output_dict' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# separate features from target variable\n",
    "X = df.loc[:,(df.columns!= 'num') & (df.columns != 'dataset') ].copy(deep=True)\n",
    "y = df.loc[: , (df.columns== 'num')].values.ravel().copy()\n",
    "\n",
    "# We would like to be able to analyse the influence of scalers, estimators, imputers and samplers on the score. Therefore, we refrain from using them as hyperparameters. Instead, we loop over all possible configurations and create separate pipelines that are logged separately in the output. In the later analysis, the parameters can still be considered as hyperparamters, but they do not have to be, thus allowing a more detailed analysis. In order to make the results comparable the cross validations and estimators etc. are seeded if possible.\n",
    "for scaler in scalers:\n",
    "    for estimator in estimators:\n",
    "        for imputer in imputers:\n",
    "            for sampler in samplers:\n",
    "\n",
    "                # combine the parameter dictionaries (| is a valid operator because the keys do not overlap)\n",
    "                parameters =  scaler.get(\"parameters\") | estimator.get(\"parameters\") | imputer.get('parameters') | general_parameters\n",
    "                # use column transformer to oneHotEncode features. Because some categorical values have very few occurences, it could happen, that features are not present in the train set but only in test. This would lead to an error if these categories would not be ignored. The columns that are oneHotEncoded are defined at runtime by the given lambda because it could happen that a column that should be oneHotEncoded was dropped in an earlier pipeline step. Because not all features are processed, the remainders are passed through instead of being dropped (default behaviour).\n",
    "                oneHotEncoder = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                            ('oneHotEncoder', OneHotEncoder(handle_unknown='ignore'), lambda X : [value for value in one_hot_encoded_features if value in X.columns]),\n",
    "                        ], remainder='passthrough')\n",
    "                #build the pipeline\n",
    "                pipeline = Pipeline(steps=[\n",
    "                    ('fix_encoding_errors', FixCommonEncodingErrors()),\n",
    "                    ('transform_smoke', DataframeSmokeTransformer()),\n",
    "                    ('drop_columns', DropColumnsBasedOnMinimumPercentageToBeDropped()),\n",
    "                    ('impute', imputer.get('imputer')),\n",
    "                    ('oneHotEncoder', oneHotEncoder),\n",
    "                    ('scaler', scaler.get('scaler')),\n",
    "                    ('sampler', sampler),\n",
    "                    ('estimator', estimator.get(\"estimator\"))\n",
    "                ])\n",
    "                # create the inner grid search instance. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV parameter cv)\n",
    "                grid_search_estimator = GridSearchCV(pipeline, parameters, scoring='roc_auc', cv=10, error_score='raise', n_jobs=-1, verbose= 0)\n",
    "                # if a configuration fails it is skipped and a comment is placed in the output\n",
    "                try:\n",
    "                    print(f\"GridSearch for {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__}\")\n",
    "                    startTime = time.time()\n",
    "                    # Start nested cross validation. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html parameter cv)\n",
    "                    auc_best = cross_val_score(grid_search_estimator, X, y, cv=10, scoring=make_scorer(classification_report_with_auc_score), error_score='raise', verbose = 2, n_jobs=1)\n",
    "                    # determine best hyperparameters\n",
    "                    grid_search_estimator.fit(X, y)\n",
    "                    executionTime = (time.time() - startTime)\n",
    "                except Exception as e:\n",
    "                    # add comment for failed execution to output_dict\n",
    "                    print(f\"Skipping the combination of {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__} because:\")\n",
    "                    print(str(e))\n",
    "                    output_dict = {}\n",
    "                    output_dict[\"scaler\"]= scaler.get('scaler').__class__.__name__\n",
    "                    output_dict[\"estimator\"] = estimator.get('estimator').__class__.__name__\n",
    "                    output_dict[\"imputer\"] = imputer.get('imputer').__class__.__name__\n",
    "                    output_dict[\"sampler\"] = sampler.__class__.__name__\n",
    "                    output_dict[\"reason\"] = str(e)\n",
    "                else:\n",
    "                    # execution was successful. Print results and best configuration\n",
    "                    print(f\"auc for {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__} = {auc_best.mean() * 100.0}\")\n",
    "                    display(grid_search_estimator.best_params_)\n",
    "                    # create output_dict\n",
    "                    output_dict = {}\n",
    "                    output_dict[\"scaler\"]= scaler.get('scaler').__class__.__name__\n",
    "                    output_dict[\"estimator\"] = estimator.get('estimator').__class__.__name__\n",
    "                    output_dict[\"imputer\"] = imputer.get('imputer').__class__.__name__\n",
    "                    output_dict[\"sampler\"] = sampler.__class__.__name__\n",
    "                    output_dict[\"X_shape\"] = X.shape\n",
    "                    output_dict[\"one_hot_encoded_features\"] = one_hot_encoded_features\n",
    "                    output_dict[\"parameters\"] = parameters\n",
    "                    output_dict[\"auc_mean\"] = auc_best.mean() * 100\n",
    "                    output_dict[\"execution_time_in_seconds\"] = executionTime\n",
    "                    output_dict[\"best_params\"] = grid_search_estimator.best_params_\n",
    "                    # read results of outer loop from cv from pickle and add to output dictionary\n",
    "                    with open(\"temp.pickle\", \"rb\") as temp_file:\n",
    "                        report = pickle.load(temp_file)\n",
    "                        output_dict[\"auc\"] = report['auc']\n",
    "                        output_dict[\"classification_report\"] = report['classification_report']\n",
    "                        output_dict[\"confusion_matrix\"] = report['confusion_matrix']\n",
    "                finally:\n",
    "                    # read measurements from output.json if it exists, otherwise create empty list\n",
    "                    if os.path.exists('output.json'):\n",
    "                        with open(\"output.json\", \"r\") as file:\n",
    "                            file_dict = json.load(file)\n",
    "                            measurements  = file_dict.get('measurements')\n",
    "                    else:\n",
    "                        measurements = []\n",
    "                    # append new measurements to array\n",
    "                    measurements.append(output_dict)\n",
    "                    # write to output.json using CustomEncoder\n",
    "                    with open(\"output.json\", \"w\") as file:\n",
    "                        json.dump({\"measurements\": measurements}, file, cls= CustomEncoder)\n",
    "                    # remove temp.pickle if it exists\n",
    "                    if os.path.exists('temp.pickle'):\n",
    "                        os.remove('temp.pickle')\n",
    "\n",
    "\n",
    "\n",
    "        print(\"-----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f29bcd13b203cd2f3ad884218deb9474aa7a618a643a4b1b589e349769171ce9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
