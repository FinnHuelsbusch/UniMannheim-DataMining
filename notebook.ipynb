{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "## Variables for configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_features = ['cp','restecg', 'slope','ca', 'restwm']\n",
    "# list the datasets that should be used in the current run\n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"long-beach-va\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "# set pandas to show all columns of the df when using the display function\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to read the dataset into a csv formatted string\n",
    "# the name is used as a delimiter here because it is the last feature and common among all entrys \n",
    "def read_raw_data(file_path:str):\n",
    "    with open(file_path) as file:\n",
    "        file_string = file.read()\n",
    "        # remove unnecessary linebreaks\n",
    "        file_string = file_string.replace(\"\\n\",\" \")\n",
    "        # break lines after name to separate measurements by line (name is a constant and the last attribute)\n",
    "        file_string = file_string.replace(\"name \",\"name\\n\")\n",
    "        # separate columns by \",\" instead of \" \".\n",
    "        file_string = file_string.replace(\" \",\",\")\n",
    "        return file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the specified datasets into the df \n",
    "from io import StringIO\n",
    "df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(StringIO(read_raw_data(\"./Data/\"+ dataset +\".data\")), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    df = pd.concat([df,dataset_df ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"id\", \"ccf\", \"age\", \"sex\", \"painloc\", \"painexer\" , \"relrest\" , \"pncaden\" , \"cp\", \"trestbps\", \"htn\", \"chol\", \"smoke\", \"cigs\", \"years\", \"fbs\", \"dm\", \"famhist\", \"restecg\", \"ekgmo\", \"ekgday\", \"ekgyr\", \"dig\", \"prop\", \"nitr\", \"pro\", \"diuretic\", \"proto\", \"thaldur\", \"thaltime\", \"met\", \"thalach\", \"thalrest\", \"tpeakbps\", \"tpeakbpd\", \"dummy\", \"trestbpd\", \"exang\", \"xhypo\", \"oldpeak\", \"slope\", \"rldv5\", \"rldv5e\", \"ca\", \"restckm\", \"exerckm\", \"restef\", \"restwm\", \"exeref\", \"exerwm\", \"thal\", \"thalsev\", \"thalpul\", \"earlobe\", \"cmo\", \"cday\", \"cyr\", \"num\", \"lmt\", \"ladprox\", \"laddist\", \"diag\", \"cxmain\", \"ramus\", \"om1\", \"om2\", \"rcaprox\", \"rcadist\", \"lvx1\", \"lvx2\", \"lvx3\", \"lvx4\", \"lvf\", \"cathef\", \"junk\", \"name\", \"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "       id  ccf  age  sex  painloc  painexer  relrest  pncaden  cp  trestbps  \\\n0    1254    0   40    1      1.0       0.0      0.0      NaN   2     140.0   \n1    1255    0   49    0      1.0       0.0      0.0      NaN   3     160.0   \n2    1256    0   37    1      1.0       0.0      0.0      NaN   2     130.0   \n3    1257    0   48    0      1.0       1.0      1.0      NaN   4     138.0   \n4    1258    0   54    1      1.0       0.0      1.0      NaN   3     150.0   \n..    ...  ...  ...  ...      ...       ...      ...      ...  ..       ...   \n894   200    0   54    0      1.0       1.0      1.0      NaN   4     127.0   \n895   201    0   62    1      0.0       0.0      0.0      NaN   1       NaN   \n896   202    0   55    1      1.0       1.0      1.0      NaN   4     122.0   \n897   116    0   58    1      1.0       1.0      1.0      NaN   4       NaN   \n898   160    0   62    1      1.0       0.0      0.0      NaN   2     120.0   \n\n     htn   chol  smoke  cigs  years  fbs   dm  famhist  restecg  ekgmo  \\\n0    0.0  289.0    NaN   NaN    NaN  0.0  NaN      NaN      0.0   12.0   \n1    1.0  180.0    NaN   NaN    NaN  0.0  NaN      NaN      0.0   11.0   \n2    0.0  283.0    NaN   NaN    NaN  0.0  NaN      NaN      1.0   11.0   \n3    0.0  214.0    NaN   NaN    NaN  0.0  NaN      NaN      0.0    9.0   \n4    0.0    NaN    NaN   NaN    NaN  0.0  NaN      NaN      0.0    7.0   \n..   ...    ...    ...   ...    ...  ...  ...      ...      ...    ...   \n894  0.0  333.0    0.0   0.0    0.0  1.0  NaN      1.0      1.0    6.0   \n895  0.0  139.0    1.0  15.0   30.0  0.0  NaN      0.0      1.0    NaN   \n896  1.0  223.0    1.0  20.0   40.0  1.0  NaN      0.0      1.0    5.0   \n897  0.0  385.0    0.0  10.0   20.0  1.0  1.0      1.0      2.0    NaN   \n898  1.0  254.0    0.0   0.0    0.0  0.0  NaN      0.0      2.0    1.0   \n\n     ekgday  ekgyr  dig  prop  nitr  pro  diuretic  proto  thaldur  thaltime  \\\n0      16.0   84.0  0.0   0.0   0.0  0.0       0.0  150.0     18.0       NaN   \n1      16.0   84.0  0.0   0.0   0.0  0.0       0.0    NaN     10.0       9.0   \n2      21.0   84.0  0.0   0.0   0.0  0.0       0.0  100.0     10.0       NaN   \n3      21.0   84.0  0.0   0.0   0.0  0.0       0.0   50.0      5.0       4.0   \n4      25.0   84.0  0.0   0.0   1.0  1.0       0.0   25.0      2.0       NaN   \n..      ...    ...  ...   ...   ...  ...       ...    ...      ...       ...   \n894     6.0   83.0  0.0   1.0   1.0  0.0       0.0    1.0      7.5       NaN   \n895     NaN    NaN  NaN   NaN   NaN  NaN       NaN    NaN      NaN       NaN   \n896     2.0   86.0  0.0   1.0   1.0  0.0       1.0    5.0      5.3       NaN   \n897     NaN    NaN  NaN   NaN   NaN  NaN       NaN    NaN      NaN       NaN   \n898    24.0   83.0  0.0   1.0   0.0  0.0       0.0    1.0      6.7       NaN   \n\n     met  thalach  thalrest  tpeakbps  tpeakbpd  dummy  trestbpd  exang  \\\n0    7.0    172.0      86.0     200.0     110.0  140.0      86.0    0.0   \n1    7.0    156.0     100.0     220.0     106.0  160.0      90.0    0.0   \n2    5.0     98.0      58.0     180.0     100.0  130.0      80.0    0.0   \n3    4.0    108.0      54.0     210.0     106.0  138.0      86.0    1.0   \n4    3.0    122.0      74.0     130.0     100.0  150.0      90.0    0.0   \n..   ...      ...       ...       ...       ...    ...       ...    ...   \n894  8.0    154.0      83.0     158.0      84.0  127.0      78.0    0.0   \n895  NaN      NaN       NaN       NaN       NaN    NaN       NaN    NaN   \n896  5.0    100.0      74.0     210.0     100.0  122.0      70.0    0.0   \n897  NaN      NaN       NaN       NaN       NaN    NaN       NaN    NaN   \n898  7.0     93.0      67.0     164.0     110.0  120.0      80.0    1.0   \n\n     xhypo  oldpeak  slope  rldv5  rldv5e  ca  restckm  exerckm  restef  \\\n0      0.0      0.0    NaN   26.0    20.0 NaN      NaN      NaN     NaN   \n1      0.0      1.0    2.0   14.0    13.0 NaN      NaN      NaN     NaN   \n2      0.0      0.0    NaN   17.0    14.0 NaN      NaN      NaN     NaN   \n3      0.0      1.5    2.0   19.0    22.0 NaN      NaN      NaN     NaN   \n4      1.0      0.0    NaN   13.0     9.0 NaN      NaN      NaN     NaN   \n..     ...      ...    ...    ...     ...  ..      ...      ...     ...   \n894    0.0      0.0    NaN   20.0    20.0 NaN      NaN      NaN     NaN   \n895    NaN      NaN    NaN    NaN     NaN NaN      NaN      NaN    0.41   \n896    0.0      0.0    NaN    6.0     4.0 NaN      NaN      NaN    0.39   \n897    NaN      NaN    NaN    NaN     NaN NaN      NaN      NaN     NaN   \n898    0.0      0.0    NaN   21.0    17.0 NaN      NaN      NaN     NaN   \n\n     restwm  exeref  exerwm  thal  thalsev  thalpul  earlobe   cmo  cday  \\\n0       NaN     NaN     NaN   NaN      NaN      NaN      NaN  12.0  20.0   \n1       NaN     NaN     NaN   NaN      NaN      NaN      NaN  11.0  20.0   \n2       NaN     NaN     NaN   NaN      NaN      NaN      NaN  11.0  26.0   \n3       NaN     NaN     NaN   NaN      NaN      NaN      NaN   9.0  30.0   \n4       NaN     NaN     NaN   NaN      NaN      NaN      NaN   7.0  30.0   \n..      ...     ...     ...   ...      ...      ...      ...   ...   ...   \n894     NaN     NaN     NaN   NaN      NaN      NaN      NaN   6.0  29.0   \n895     1.0     NaN     NaN   NaN      NaN      NaN      NaN   5.0  26.0   \n896     3.0     NaN     NaN   6.0      2.0      NaN      NaN   4.0  17.0   \n897     NaN     NaN     NaN   NaN      NaN      NaN      NaN   2.0  16.0   \n898     NaN     NaN     NaN   NaN      NaN      NaN      NaN   6.0  20.0   \n\n      cyr  num  lmt  ladprox  laddist  diag  cxmain  ramus  om1  om2  rcaprox  \\\n0    84.0    0  NaN      NaN      NaN   NaN     NaN    NaN  NaN  NaN      NaN   \n1    84.0    1  NaN      NaN      2.0   NaN     NaN    NaN  NaN  NaN      NaN   \n2    84.0    0  NaN      NaN      NaN   NaN     NaN    NaN  NaN  NaN      NaN   \n3    84.0    3  NaN      2.0      NaN   NaN     2.0    NaN  NaN  NaN      2.0   \n4    84.0    0  NaN      NaN      NaN   NaN     1.0    NaN  NaN  NaN      1.0   \n..    ...  ...  ...      ...      ...   ...     ...    ...  ...  ...      ...   \n894  83.0    1  1.0      1.0      1.0   1.0     2.0    1.0  1.0  1.0      1.0   \n895  86.0    0  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0   \n896  86.0    2  1.0      2.0      1.0   1.0     1.0    1.0  1.0  1.0      2.0   \n897  83.0    0  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0   \n898  83.0    1  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      2.0   \n\n     rcadist  lvx1  lvx2  lvx3  lvx4  lvf  cathef  junk  name        dataset  \n0        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n1        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n2        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n3        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n4        NaN   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name      hungarian  \n..       ...   ...   ...   ...   ...  ...     ...   ...   ...            ...  \n894      1.0   1.0   1.0   1.0   1.0  1.0    0.76   5.6  name  long-beach-va  \n895      1.0   1.0   1.0   1.0   1.0  2.0    0.62   3.5  name  long-beach-va  \n896      1.0   1.0   1.0   1.0   1.0  1.0    0.69   5.6  name  long-beach-va  \n897      1.0   1.0   1.0   1.0   1.0  1.0    0.81   6.0  name  long-beach-va  \n898      1.0   1.0   1.0   1.0   1.0  1.0     NaN   NaN  name  long-beach-va  \n\n[899 rows x 77 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ccf</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>painloc</th>\n      <th>painexer</th>\n      <th>relrest</th>\n      <th>pncaden</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>htn</th>\n      <th>chol</th>\n      <th>smoke</th>\n      <th>cigs</th>\n      <th>years</th>\n      <th>fbs</th>\n      <th>dm</th>\n      <th>famhist</th>\n      <th>restecg</th>\n      <th>ekgmo</th>\n      <th>ekgday</th>\n      <th>ekgyr</th>\n      <th>dig</th>\n      <th>prop</th>\n      <th>nitr</th>\n      <th>pro</th>\n      <th>diuretic</th>\n      <th>proto</th>\n      <th>thaldur</th>\n      <th>thaltime</th>\n      <th>met</th>\n      <th>thalach</th>\n      <th>thalrest</th>\n      <th>tpeakbps</th>\n      <th>tpeakbpd</th>\n      <th>dummy</th>\n      <th>trestbpd</th>\n      <th>exang</th>\n      <th>xhypo</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>rldv5</th>\n      <th>rldv5e</th>\n      <th>ca</th>\n      <th>restckm</th>\n      <th>exerckm</th>\n      <th>restef</th>\n      <th>restwm</th>\n      <th>exeref</th>\n      <th>exerwm</th>\n      <th>thal</th>\n      <th>thalsev</th>\n      <th>thalpul</th>\n      <th>earlobe</th>\n      <th>cmo</th>\n      <th>cday</th>\n      <th>cyr</th>\n      <th>num</th>\n      <th>lmt</th>\n      <th>ladprox</th>\n      <th>laddist</th>\n      <th>diag</th>\n      <th>cxmain</th>\n      <th>ramus</th>\n      <th>om1</th>\n      <th>om2</th>\n      <th>rcaprox</th>\n      <th>rcadist</th>\n      <th>lvx1</th>\n      <th>lvx2</th>\n      <th>lvx3</th>\n      <th>lvx4</th>\n      <th>lvf</th>\n      <th>cathef</th>\n      <th>junk</th>\n      <th>name</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1254</td>\n      <td>0</td>\n      <td>40</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>140.0</td>\n      <td>0.0</td>\n      <td>289.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>16.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>150.0</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>172.0</td>\n      <td>86.0</td>\n      <td>200.0</td>\n      <td>110.0</td>\n      <td>140.0</td>\n      <td>86.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>26.0</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>20.0</td>\n      <td>84.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1255</td>\n      <td>0</td>\n      <td>49</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>160.0</td>\n      <td>1.0</td>\n      <td>180.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>16.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>156.0</td>\n      <td>100.0</td>\n      <td>220.0</td>\n      <td>106.0</td>\n      <td>160.0</td>\n      <td>90.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>14.0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>20.0</td>\n      <td>84.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1256</td>\n      <td>0</td>\n      <td>37</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>130.0</td>\n      <td>0.0</td>\n      <td>283.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>11.0</td>\n      <td>21.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>98.0</td>\n      <td>58.0</td>\n      <td>180.0</td>\n      <td>100.0</td>\n      <td>130.0</td>\n      <td>80.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>26.0</td>\n      <td>84.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1257</td>\n      <td>0</td>\n      <td>48</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>138.0</td>\n      <td>0.0</td>\n      <td>214.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>21.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>108.0</td>\n      <td>54.0</td>\n      <td>210.0</td>\n      <td>106.0</td>\n      <td>138.0</td>\n      <td>86.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>19.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>30.0</td>\n      <td>84.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1258</td>\n      <td>0</td>\n      <td>54</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>25.0</td>\n      <td>84.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>122.0</td>\n      <td>74.0</td>\n      <td>130.0</td>\n      <td>100.0</td>\n      <td>150.0</td>\n      <td>90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>30.0</td>\n      <td>84.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>hungarian</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>200</td>\n      <td>0</td>\n      <td>54</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>127.0</td>\n      <td>0.0</td>\n      <td>333.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>83.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>7.5</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>154.0</td>\n      <td>83.0</td>\n      <td>158.0</td>\n      <td>84.0</td>\n      <td>127.0</td>\n      <td>78.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>29.0</td>\n      <td>83.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.76</td>\n      <td>5.6</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>201</td>\n      <td>0</td>\n      <td>62</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>139.0</td>\n      <td>1.0</td>\n      <td>15.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.41</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>26.0</td>\n      <td>86.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.62</td>\n      <td>3.5</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>202</td>\n      <td>0</td>\n      <td>55</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>122.0</td>\n      <td>1.0</td>\n      <td>223.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>40.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>86.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>5.3</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>100.0</td>\n      <td>74.0</td>\n      <td>210.0</td>\n      <td>100.0</td>\n      <td>122.0</td>\n      <td>70.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.39</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>17.0</td>\n      <td>86.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.69</td>\n      <td>5.6</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>116</td>\n      <td>0</td>\n      <td>58</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>385.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>20.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>16.0</td>\n      <td>83.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.81</td>\n      <td>6.0</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>160</td>\n      <td>0</td>\n      <td>62</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>120.0</td>\n      <td>1.0</td>\n      <td>254.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>24.0</td>\n      <td>83.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.7</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>93.0</td>\n      <td>67.0</td>\n      <td>164.0</td>\n      <td>110.0</td>\n      <td>120.0</td>\n      <td>80.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>21.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>20.0</td>\n      <td>83.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>name</td>\n      <td>long-beach-va</td>\n    </tr>\n  </tbody>\n</table>\n<p>899 rows Ã— 77 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace -9 by NaN (according to Data/heart-disease.names)\n",
    "df.replace(-9,np.float64(\"NaN\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# we want to predict whether a patient has any heart disease, not the type/degree of heart disease as recommended by the UCI https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "df[df[\"num\"]>1] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment of different scales in the datasets\n",
    "the reasons for this processing are laid out further in the analysis notebook\n",
    "## met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data:\n",
    "sns.boxplot(x=\"met\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# the measurements of switzerland do not seem valid -> replace with NaN\n",
    "df.loc[df[\"dataset\"] == \"switzerland\", \"met\"] = np.float64(\"NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rldv5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data: \n",
    "sns.boxplot(x=\"rldv5e\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# the measurements of cleveland do not seem valid -> replace with NaN\n",
    "df.loc[df[\"dataset\"] == \"cleveland\", \"rldv5e\"] = np.float64(\"NaN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "irrelevant_columns = [\n",
    "    \"id\", # A id is not relevant for a model\n",
    "    \"ccf\", # the social security number does not influence if you have a heart disease or not\n",
    "    \"pncaden\", # sum of painlox painexer relrest -> the features are already in the dataset -> drop because it is a duplicate\n",
    "    \"ekgmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"name\" # Constant\n",
    "]\n",
    "df.drop(irrelevant_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unexplained_columns = [\n",
    "    \"restckm\", # irrelevant according to the uci\n",
    "    \"exerckm\", # irrelevant according to the uci\n",
    "    \"thalsev\", # irrelevant according to the uci\n",
    "    \"thalpul\", # irrelevant according to the uci\n",
    "    \"earlobe\", # Constant\n",
    "    \"lvx1\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx2\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx3\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx4\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvf\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"dummy\", # no description available -> from the name does not seem relevant\n",
    "    'junk'\n",
    "]\n",
    "df.drop(unexplained_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hidden_identifier = [\n",
    "    'lmt',      # Left main truck\n",
    "    'ladprox',  # Proximal left anterior descending artery\n",
    "    'laddist',  # Distal left anterior descending artery\n",
    "    'diag',     # Diagonal branches\n",
    "    'cxmain',   # Circumflex\n",
    "    'ramus',    # Ramus intermedius\n",
    "    'om1',      # First obtuse marginal branch\n",
    "    'om2',      # Second obtuse marginal branch\n",
    "    'rcaprox',  # Proximal right coronary artery\n",
    "    'rcadist',  # Distal right coronary artery\n",
    "]\n",
    "df.drop(hidden_identifier, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from  sklearn.naive_bayes import *\n",
    "\n",
    "estimators=[\n",
    "    # {\"estimator\": CatBoostClassifier(random_state=42, thread_count=-1, silent= True), \"parameters\": {'estimator__depth':[None] + [*range(1,200)],\n",
    "    #                                                                                                  'estimator__n_estimators':range(10,1000, 100),\n",
    "    #                                                                                                  'estimator__learning_rate':[0.001,0.01,0.1,0.2,0.3],\n",
    "    #                                                                                                  'estimator__l2_leaf_reg':range(5,100, 5),\n",
    "    #                                                                                                  'estimator__border_count':range(5,200, 5),\n",
    "    #                                                                                                  'estimator__ctr_border_count':range(5,200, 5)\n",
    "    #                                                                                                  }},\n",
    "    # {\"estimator\": XGBClassifier(random_state=42, n_jobs=1), \"parameters\": {'estimator__max_depth': [None] + [*range(1,200)],\n",
    "    #                                                                        'estimator__n_estimators': range(10,1000, 100),\n",
    "    #                                                                         'estimator__learning_rate':[0.001,0.01,0.1,0.2,0.3]}},\n",
    "    # {\"estimator\": SVC(random_state=42, tol=0.01), \"parameters\": {'estimator__C': [110,120,130,140,150],\n",
    "    #                                                              'estimator__gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    #                                                              'estimator__degree': [3,4,5,6],\n",
    "    #                                                              'estimator__kernel':['linear', 'rbf', 'poly', 'sigmoid'] }}, # '\n",
    "    # {\"estimator\": BernoulliNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1)}},\n",
    "    # {\"estimator\": CategoricalNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1)}},\n",
    "    # {\"estimator\": ComplementNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1),\n",
    "    #                                              'estimator__norm':[True,False]}},\n",
    "    # {\"estimator\": GaussianNB(), \"parameters\": {}},\n",
    "    # {\"estimator\": MultinomialNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1)}},\n",
    "    # {\"estimator\": DecisionTreeClassifier(random_state=42), \"parameters\": {'estimator__criterion':['gini','entropy', 'log_loss'],\n",
    "    #                                                                       'estimator__max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150],\n",
    "    #                                                                       'estimator__min_samples_split': range(2,20),\n",
    "    #                                                                       'estimator__min_samples_leaf': range(2,20)}},\n",
    "    {\"estimator\": KNeighborsClassifier(), \"parameters\": {'estimator__n_neighbors': range(2, 100,5),\n",
    "                                                         'estimator__weights': ['uniform','distance'],\n",
    "                                                         'estimator__p': [1,2]}},\n",
    "    # {\"estimator\": RandomForestClassifier(random_state=42, n_jobs=1), \"parameters\": {'estimator__n_estimators':range(10,1000, 100)}},\n",
    "    # {\"estimator\": SGDClassifier(max_iter=1000000), \"parameters\": {'estimator__loss':['log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    #                                               'estimator__penalty':['l1','l2','elasticnet'],\n",
    "    #                                               'estimator__alpha' : np.arange(1,40,1)}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "scalers = [\n",
    "    {\"scaler\": MaxAbsScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": MinMaxScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": Normalizer(), \"parameters\": {'scaler__norm': ['l1', 'l2', 'max']}},\n",
    "    # box-cox is not used because the dataset contains negative values\n",
    "    {\"scaler\": PowerTransformer(), \"parameters\": {'scaler__standardize':[True,False]}},\n",
    "    # quantile-range is not used for selecting the model in order to reduce compute time\n",
    "    {\"scaler\": RobustScaler(), \"parameters\": {'scaler__with_centering': [ True, False],'scaler__with_scaling': [ True, False]}},\n",
    "    {\"scaler\": StandardScaler(), \"parameters\": {'scaler__with_mean': [ True, False],'scaler__with_std': [ True, False]}},\n",
    "    {\"scaler\": 'passthrough', \"parameters\": {}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "imputers = [\n",
    "    {\"imputer\": SimpleImputer(), \"parameters\": {'impute__strategy' : ['mean', 'median', 'most_frequent']}},\n",
    "    # KNN imputer is not used after inspection of the runtime with the KNN classifier (see KNN_classifier_with_KNN_and_simple_imputer.json)\n",
    "    # {\"imputer\": KNNImputer(), \"parameters\": {'impute__n_neighbors': range(2, 10,1)}},\n",
    "    # iterative imputer is not used because bugs were observed during the usage of this experimental feature\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "samplers = ['passthrough', RandomOverSampler(),RandomUnderSampler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "general_parameters = {\n",
    "    #values are selected based on analysis in Analyse.ipynb\n",
    "    'drop_columns__minimum_percentage_to_be_dropped': [0,4,8,20,35,60,75,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns smoke, cigs and years describe whether a respondent smokes or not. Smoke does this by being binary coded, while years describes the number of years a person has smoked. Cigs describes how many cigarettes the person smokes a day. Due to the high number of missing values in smoke, it is enriched with the years and cigs columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DataframeSmokeTransformer:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        # we do not enrich smoke if cigs and years are conflicting\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of years is 0 and smoke does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] == 0) & ~(input_df['cigs'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of years is larger than 0 and smoke does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] > 0) & (input_df['cigs'] != 0),'smoke'] = 1\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of smoke is 0 and years does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] == 0) & ~(input_df['years'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of cigs is larger than 0 and years does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] > 0) & (input_df['years'] != 0),'smoke'] = 1\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # there is nothing to be fitted here because this handling is not split specific\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "class DropColumnsBasedOnMinimumPercentageToBeDropped:\n",
    "    def __init__(self):\n",
    "        self.minimum_percentage_to_be_dropped = 100\n",
    "        self.fitted = False\n",
    "        self.valuesToKeep = []\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.minimum_percentage_to_be_dropped = params.get('minimum_percentage_to_be_dropped')\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        if self.fitted:\n",
    "            return input_df[input_df.columns.intersection(self.valuesToKeep)]\n",
    "        else:\n",
    "            raise NotFittedError()\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # calculate percentage of missing values for each column and store in a dictionary\n",
    "        percentage_missing = (X.isna().sum()/len(df)*100).to_dict()\n",
    "        # generate list of columns to keep\n",
    "        self.valuesToKeep = [key for key, val in percentage_missing.items() if val <= self.minimum_percentage_to_be_dropped]\n",
    "        self.fitted = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FixCommonEncodingErrors:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        input_df = input_df.copy(deep=True)\n",
    "        # if cholesterin is 0 it was not measured\n",
    "        input_df.loc[input_df['chol'] == 0,'chol'] =  np.float64(\"NaN\")\n",
    "        # leave the dead ones behind\n",
    "        # drop entries with a blood pressure of 0\n",
    "        input_df.loc[input_df['trestbps'] == 0,'trestbps'] =  np.float64(\"NaN\")\n",
    "        # is a binary variable (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[df['prop'].isin([0,1]) == False,'prop' ] = np.float64(\"NaN\")\n",
    "        # is a variable that has the values 0-3 by definition  (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[input_df['ca'] >3 ,'ca'] =  np.float64(\"NaN\")\n",
    "        # transform proto according to possible values from data/ask-detrano\n",
    "        input_df.loc[input_df['proto'] == 200,'proto'] =  9\n",
    "        input_df.loc[input_df['proto'] == 175,'proto'] =  8\n",
    "        input_df.loc[input_df['proto'] == 150,'proto'] =  7\n",
    "        input_df.loc[input_df['proto'] == 130,'proto'] =  6\n",
    "        input_df.loc[input_df['proto'] == 125,'proto'] =  5\n",
    "        input_df.loc[input_df['proto'] == 100,'proto'] = 4\n",
    "        input_df.loc[input_df['proto'] == 75,'proto'] = 3\n",
    "        input_df.loc[input_df['proto'] == 50,'proto'] = 2\n",
    "        input_df.loc[input_df['proto'] == 50,'proto'] = 1\n",
    "        #set all other values to NaN\n",
    "        input_df.loc[input_df['proto'].isin([*range(1,13)]) == False, 'proto'] = np.float64(\"NaN\")\n",
    "\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# assumption the dictionaries are of equal structure\n",
    "def merge_dict(dict1, dict2):\n",
    "    for key, val in dict1.items():\n",
    "        # merge nested dictionaries\n",
    "        if type(val) == dict:\n",
    "            dict1[key] = merge_dict(dict1[key], dict2[key])\n",
    "        # if value of dict1 is a list -> append values of dict2[key] to that list\n",
    "        elif type(val) == list:\n",
    "            if type(dict2[key]) == list:\n",
    "                dict1[key] = [ *dict1[key], *dict2[key]]\n",
    "            else:\n",
    "                dict1[key] = [*dict1[key], dict2[key]]\n",
    "        else:\n",
    "            # merge values into a new list\n",
    "            dict1[key] = [val, dict2[key]]\n",
    "\n",
    "    return dict1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# It is necessary to write a separate score function to obtain and save results from the respective cross validations later on (outer loop of nested cv).\n",
    "# This procedure requires working with pickle, as it is not possible to interact with data structures from the notebook (even if they are marked as global), as make_scorer later creates a deepCopy of this function and thus the data structures are also copied. The same applies to the parameters that could be passed to this function in the makeScorer function.\n",
    "def classification_report_with_auc_score(y_true, y_pred):\n",
    "    # calculate the score that will be returned to the cross validation to obtain the optimal hyperparameters\n",
    "    current_roc_auc_score = roc_auc_score(y_true, y_pred)\n",
    "    #transform confusion matrix to dictionary\n",
    "    confusion_matrix_dict = {}\n",
    "    for idxRow, row in np.ndenumerate(confusion_matrix(y_true, y_pred)):\n",
    "        confusion_matrix_dict[str(idxRow)] = row\n",
    "    # check if pickle was created by another cross validation loop\n",
    "    if os.path.exists('temp.pickle'):\n",
    "        with open(\"temp.pickle\", \"rb\") as temp_file:\n",
    "            # read pickled dictionary of previous cross validation loop\n",
    "            report = pickle.load(temp_file)\n",
    "            # append current score\n",
    "            report[\"auc\"].append(current_roc_auc_score)\n",
    "            # merge classification reports\n",
    "            report['classification_report'] = merge_dict(report['classification_report'], classification_report(y_true, y_pred, output_dict=True))\n",
    "            # merge confusion matrix dictionaries\n",
    "            report['confusion_matrix'] = merge_dict(report['confusion_matrix'], confusion_matrix_dict)\n",
    "    else:\n",
    "        #create dictionary for first pickle\n",
    "        report = {'classification_report': classification_report(y_true, y_pred, output_dict=True),\n",
    "                  \"auc\": [current_roc_auc_score],\n",
    "                  'confusion_matrix': confusion_matrix_dict\n",
    "                  }\n",
    "    # write report dictionary to pickle-file\n",
    "    with open('temp.pickle', 'wb') as temp_file:\n",
    "        pickle.dump(report, temp_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # return calculated roc_auc_score for evaluation in cross validation\n",
    "    return current_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from imblearn.base import BaseSampler\n",
    "import json\n",
    "\n",
    "#custom Encoder for serialization of output\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if type(obj) == range:\n",
    "            return [*obj]\n",
    "        if isinstance(obj, BaseSampler):\n",
    "            return obj.__class__.__name__\n",
    "        return super(CustomEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for MaxAbsScaler, KNeighborsClassifier,NoneType and str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for MaxAbsScaler, KNeighborsClassifier,NoneType and str = 51.037562535801705\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 8,\n 'estimator__n_neighbors': 17,\n 'estimator__p': 1,\n 'estimator__weights': 'distance',\n 'impute__strategy': 'median'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for MaxAbsScaler, KNeighborsClassifier,NoneType and RandomOverSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for MaxAbsScaler, KNeighborsClassifier,NoneType and RandomOverSampler = 55.380770135913934\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 35,\n 'estimator__n_neighbors': 17,\n 'estimator__p': 1,\n 'estimator__weights': 'distance',\n 'impute__strategy': 'most_frequent'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for MaxAbsScaler, KNeighborsClassifier,NoneType and RandomUnderSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for MaxAbsScaler, KNeighborsClassifier,NoneType and RandomUnderSampler = 53.37802431477312\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 4,\n 'estimator__n_neighbors': 12,\n 'estimator__p': 1,\n 'estimator__weights': 'distance',\n 'impute__strategy': 'mean'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# separate features from target variable\n",
    "X = df.loc[:,(df.columns!= 'num') & (df.columns != 'dataset') ].copy(deep=True)\n",
    "y = df.loc[: , (df.columns== 'num')].values.ravel().copy()\n",
    "\n",
    "# We would like to be able to analyse the influence of scalers, estimators, imputers and samplers on the score. Therefore, we refrain from using them as hyperparameters. Instead, we loop over all possible configurations and create separate pipelines that are logged separately in the output. In the later analysis, the parameters can still be considered as hyperparamters, but they do not have to be, thus allowing a more detailed analysis. In order to make the results comparable the cross validations and estimators etc. are seeded if possible.\n",
    "for scaler in scalers:\n",
    "    for estimator in estimators:\n",
    "        for imputer in imputers:\n",
    "            for sampler in samplers:\n",
    "\n",
    "                # combine the parameter dictionaries (| is a valid operator because the keys do not overlap)\n",
    "                parameters =  scaler.get(\"parameters\") | estimator.get(\"parameters\") | imputer.get('parameters') | general_parameters\n",
    "                # use column transformer to oneHotEncode features. Because some categorical values have very few occurences, it could happen, that features are not present in the train set but only in test. This would lead to an error if these categories would not be ignored. The columns that are oneHotEncoded are defined at runtime by the given lambda because it could happen that a column that should be oneHotEncoded was dropped in an earlier pipeline step. Because not all features are processed, the remainders are passed through instead of being dropped (default behaviour).\n",
    "                oneHotEncoder = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                            ('oneHotEncoder', OneHotEncoder(handle_unknown='ignore'), lambda X : [value for value in one_hot_encoded_features if value in X.columns]),\n",
    "                        ], remainder='passthrough')\n",
    "                #build the pipeline\n",
    "                pipeline = Pipeline(steps=[\n",
    "                    ('fix_encoding_errors', FixCommonEncodingErrors()),\n",
    "                    ('transform_smoke', DataframeSmokeTransformer()),\n",
    "                    ('drop_columns', DropColumnsBasedOnMinimumPercentageToBeDropped()),\n",
    "                    ('oneHotEncoder', oneHotEncoder),\n",
    "                    ('impute', imputer.get('imputer')),\n",
    "                    ('scaler', scaler.get('scaler')),\n",
    "                    ('sampler', sampler),\n",
    "                    ('estimator', estimator.get(\"estimator\"))\n",
    "                ])\n",
    "                # create the inner grid search instance. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV parameter cv)\n",
    "                grid_search_estimator = GridSearchCV(pipeline, parameters, scoring='roc_auc', cv=10, error_score='raise', n_jobs=-1, verbose= 0)\n",
    "                # if a configuration fails it is skipped and a comment is placed in the output\n",
    "                try:\n",
    "                    print(f\"GridSearch for {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__}\")\n",
    "                    startTime = time.time()\n",
    "                    # Start nested cross validation. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html parameter cv)\n",
    "                    auc_best = cross_val_score(grid_search_estimator, X, y, cv=10, scoring=make_scorer(classification_report_with_auc_score), error_score='raise', verbose = 2, n_jobs=1)\n",
    "                    # determine best hyperparameters\n",
    "                    grid_search_estimator.fit(X, y)\n",
    "                    executionTime = (time.time() - startTime)\n",
    "                except Exception as e:\n",
    "                    # add comment for failed execution to output_dict\n",
    "                    print(f\"Skipping the combination of {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__} because:\")\n",
    "                    print(str(e))\n",
    "                    output_dict = {}\n",
    "                    output_dict[\"scaler\"]= scaler.get('scaler').__class__.__name__\n",
    "                    output_dict[\"estimator\"] = estimator.get('estimator').__class__.__name__\n",
    "                    output_dict[\"imputer\"] = imputer.get('imputer').__class__.__name__\n",
    "                    output_dict[\"sampler\"] = sampler.__class__.__name__\n",
    "                    output_dict[\"reason\"] = str(e)\n",
    "                else:\n",
    "                    # execution was successful. Print results and best configuration\n",
    "                    print(f\"auc for {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__} = {auc_best.mean() * 100.0}\")\n",
    "                    display(grid_search_estimator.best_params_)\n",
    "                    # create output_dict\n",
    "                    output_dict = {}\n",
    "                    output_dict[\"scaler\"]= scaler.get('scaler').__class__.__name__\n",
    "                    output_dict[\"estimator\"] = estimator.get('estimator').__class__.__name__\n",
    "                    output_dict[\"imputer\"] = imputer.get('imputer').__class__.__name__\n",
    "                    output_dict[\"sampler\"] = sampler.__class__.__name__\n",
    "                    output_dict[\"X_shape\"] = X.shape\n",
    "                    output_dict[\"one_hot_encoded_features\"] = one_hot_encoded_features\n",
    "                    output_dict[\"parameters\"] = parameters\n",
    "                    output_dict[\"auc_mean\"] = auc_best.mean() * 100\n",
    "                    output_dict[\"execution_time_in_seconds\"] = executionTime\n",
    "                    output_dict[\"best_params\"] = grid_search_estimator.best_params_\n",
    "                    # read results of outer loop from cv from pickle and add to output dictionary\n",
    "                    with open(\"temp.pickle\", \"rb\") as temp_file:\n",
    "                        report = pickle.load(temp_file)\n",
    "                        output_dict[\"auc\"] = report['auc']\n",
    "                        output_dict[\"classification_report\"] = report['classification_report']\n",
    "                        output_dict[\"confusion_matrix\"] = report['confusion_matrix']\n",
    "                finally:\n",
    "                    # read measurements from output.json if it exists, otherwise create empty list\n",
    "                    if os.path.exists('output.json'):\n",
    "                        with open(\"output.json\", \"r\") as file:\n",
    "                            file_dict = json.load(file)\n",
    "                            measurements  = file_dict.get('measurements')\n",
    "                    else:\n",
    "                        measurements = []\n",
    "                    # append new measurements to array\n",
    "                    measurements.append(output_dict)\n",
    "                    # write to output.json using CustomEncoder\n",
    "                    with open(\"output.json\", \"w\") as file:\n",
    "                        json.dump({\"measurements\": measurements}, file, cls= CustomEncoder)\n",
    "                    # remove temp.pickle if it exists\n",
    "                    if os.path.exists('temp.pickle'):\n",
    "                        os.remove('temp.pickle')\n",
    "\n",
    "\n",
    "\n",
    "        print(\"-----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f29bcd13b203cd2f3ad884218deb9474aa7a618a643a4b1b589e349769171ce9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
